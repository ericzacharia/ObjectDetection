{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding and Scaling Images and their Labels\n",
    "[Roboflow's Tips for Resizing and Padding](https://blog.roboflow.com/you-might-be-resizing-your-images-incorrectly/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Define the directory path\n",
    "folder = 'CAR_VS_BOS_001'\n",
    "directory = '/Users/eric/Desktop/2-Career/Projects/ObjectDetection/hockey/letterbox_and_train_valid_split/labels'\n",
    "\n",
    "# Get the list of files in the directory\n",
    "files = sorted(os.listdir(directory))\n",
    "\n",
    "for file in files:\n",
    "    file_number = file.split('_')[-1].split('.')[0]\n",
    "    file_name = file.replace(file_number, f'{str(0) * (5 - len(str(file_number)))}{file_number}').replace('frame_', f'{folder}-')\n",
    "    # print(os.path.join(directory, file), os.path.join(directory, file_name))\n",
    "    os.rename(os.path.join(directory, file), os.path.join(directory, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from letterbox_and_train_valid_split.image_multiprocessing import parallel_process\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def letterbox_image(image, padded_image_size=(2000, 2000)):\n",
    "    image_height, image_width = image.shape[:2]\n",
    "    padded_image_height, padded_image_width = padded_image_size\n",
    "    # Check if the image is smaller than the padded size\n",
    "    if image_width < padded_image_width and image_height < padded_image_height:\n",
    "        # Image is smaller, place it randomly in the padded image\n",
    "        delta_w = padded_image_width - image_width\n",
    "        delta_h = padded_image_height - image_height\n",
    "        top_pad = np.random.randint(0, delta_h)\n",
    "        bottom_pad = delta_h - top_pad\n",
    "        left_pad = np.random.randint(0, delta_w)\n",
    "        right_pad = delta_w - left_pad\n",
    "        scale = 1.0  # No scaling for smaller images\n",
    "    else:\n",
    "        # Image is larger, scale it down\n",
    "        scale = min(padded_image_width / image_width, padded_image_height / image_height)\n",
    "        new_width = int(image_width * scale)\n",
    "        new_height = int(image_height * scale)\n",
    "        image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "        delta_w = padded_image_width - new_width\n",
    "        delta_h = padded_image_height - new_height\n",
    "        top_pad = delta_h // 2\n",
    "        bottom_pad = delta_h - top_pad\n",
    "        left_pad = delta_w // 2\n",
    "        right_pad = delta_w - left_pad\n",
    "    # Apply padding\n",
    "    color = [0, 0, 0]  # Black padding\n",
    "    padded_image = cv2.copyMakeBorder(image, top_pad, bottom_pad, left_pad, right_pad, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "    return padded_image, scale, (left_pad, right_pad, top_pad, bottom_pad)\n",
    "\n",
    "def adjust_boxes(file_path, image_shape, scale, padding):\n",
    "    with open(file_path, 'r') as file:\n",
    "        boxes = [line.strip().split() for line in file.readlines()]\n",
    "    left_pad, right_pad, top_pad, bottom_pad = padding\n",
    "    adjusted_boxes = []\n",
    "    classificatons = []\n",
    "    for classificaton, cx, cy, w, h in boxes:\n",
    "        # Convert from normalized to image coordinates\n",
    "        cx, cy, w, h = [float(val) for val in [cx, cy, w, h]]\n",
    "        cx = cx * image_shape[1]  # Convert to original image width\n",
    "        cy = cy * image_shape[0]  # Convert to original image height\n",
    "        w = w * image_shape[1]\n",
    "        h = h * image_shape[0]\n",
    "        # Scale the boxes\n",
    "        cx = cx * scale + left_pad\n",
    "        cy = cy * scale + top_pad\n",
    "        w = w * scale\n",
    "        h = h * scale\n",
    "        x = int(cx - w / 2)\n",
    "        y = int(cy - h / 2)\n",
    "        width = int(w)\n",
    "        height = int(h)\n",
    "        adjusted_boxes.append((x, y, width, height))\n",
    "        classificatons.append(classificaton)\n",
    "    return classificatons, adjusted_boxes\n",
    "\n",
    "\n",
    "def draw_boxes_on_image(image, boxes):\n",
    "    for x, y, w, h in boxes:\n",
    "        top_left = (x, y)\n",
    "        bottom_right = (x + w, y + h)\n",
    "        image = cv2.rectangle(image, top_left, bottom_right, (0, 255, 0), 2)\n",
    "    return image\n",
    "\n",
    "\n",
    "def normalize_boxes(boxes, image_shape):\n",
    "    normalized_boxes = []\n",
    "    if len(boxes) > 0:\n",
    "        image_height, image_width, _ = image_shape\n",
    "        for x, y, w, h in boxes:\n",
    "            # Convert corner coordinates to center coordinates\n",
    "            cx = x + w / 2\n",
    "            cy = y + h / 2\n",
    "            # Normalize coordinates round to 5 decimal places\n",
    "            nx = round(cx / image_width, 5)\n",
    "            ny = round(cy / image_height, 5)\n",
    "            nw = round(w / image_width, 5)\n",
    "            nh = round(h / image_height, 5)\n",
    "            normalized_boxes.append((nx, ny, nw, nh))\n",
    "    return normalized_boxes\n",
    "\n",
    "\n",
    "def process_directory(input_directory, output_directory, target_size=(2000, 2000), dev=False, n=None):\n",
    "    target_width, target_height = target_size\n",
    "    output_images_directory = os.path.join(output_directory, f'images')\n",
    "    output_labels_directory = os.path.join(output_directory, f'labels')\n",
    "    annotated_images_directory = os.path.join(output_directory, f'annotated_images')\n",
    "\n",
    "    if not os.path.exists(output_images_directory):\n",
    "        os.makedirs(output_images_directory)\n",
    "    if not os.path.exists(output_labels_directory):\n",
    "        os.makedirs(output_labels_directory)\n",
    "    if not os.path.exists(annotated_images_directory):\n",
    "        os.makedirs(annotated_images_directory)\n",
    "\n",
    "    image_dir = os.path.join(input_directory, 'images')\n",
    "    label_dir = os.path.join(input_directory, 'labels')\n",
    "\n",
    "    # iterate through all files in the input directory and display the progress bar\n",
    "    file_list = sorted(os.listdir(image_dir))\n",
    "    # file_list = sorted(os.listdir(image_dir))[-5:]\n",
    "    if n is not None:\n",
    "        # sample n random files\n",
    "        file_list = np.random.choice(file_list, n, replace=False)\n",
    "    for filename in tqdm.tqdm(file_list, desc=f\"Processing Images {target_width}x{target_height}\"):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(image_dir, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            # every image that begins with '1699', scale it down have a width no greater than a random value between 3 and 15% of the target width\n",
    "            if filename.startswith('1699'):\n",
    "                scale = min(np.random.uniform(0.03, 0.10) * target_width / image.shape[1], 1.0)\n",
    "                image = cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "            padded_image, scale, padding = letterbox_image(image, target_size)\n",
    "\n",
    "            # Save the padded image\n",
    "            output_image_path = os.path.join(output_images_directory, filename)\n",
    "            cv2.imwrite(output_image_path, padded_image)\n",
    "\n",
    "            # Adjust the bounding box labels\n",
    "            label_filename = os.path.splitext(filename)[0] + '.txt'\n",
    "            label_path = os.path.join(label_dir, label_filename)\n",
    "            if os.path.exists(label_path) and label_path.endswith('.txt'):\n",
    "                try:\n",
    "                    classifications, adjusted_boxes = adjust_boxes(label_path, image.shape, scale, padding)\n",
    "                    annotated_image = draw_boxes_on_image(padded_image, adjusted_boxes)\n",
    "\n",
    "                    # Save the annotated image\n",
    "                    annotated_image_path = os.path.join(annotated_images_directory, filename)\n",
    "                    cv2.imwrite(annotated_image_path, annotated_image)\n",
    "\n",
    "                    # Save the adjusted bounding box labels\n",
    "                    output_label_path = os.path.join(output_labels_directory, label_filename)\n",
    "                    normalized_boxes = normalize_boxes(adjusted_boxes, padded_image.shape)\n",
    "                    with open(output_label_path, 'w') as f:\n",
    "                        for classification, normalized_box in zip(classifications, normalized_boxes):\n",
    "                            f.write(f\"{classification} {' '.join([str(x) for x in normalized_box])}\" + \"\\n\")\n",
    "                except UnicodeDecodeError as e:\n",
    "                    print(f\"Error reading file {label_path}: {e}\")\n",
    "                    continue  # Skip this file\n",
    "        if dev:\n",
    "            print(filename)\n",
    "            print('Image shape:', image.shape)\n",
    "            print('Padded image shape:', padded_image.shape)\n",
    "            print('Scale:', scale)\n",
    "            print('Adjusted boxes:', adjusted_boxes)\n",
    "            print('Normalized boxes:', normalized_boxes)\n",
    "            display(Image(filename=annotated_image_path))\n",
    "\n",
    "\n",
    "dev = False\n",
    "parallel_process = False\n",
    "input_directory = '/Users/eric/Desktop/2-Career/Projects/ObjectDetection/hockey/letterbox_and_train_valid_split'\n",
    "n_processes = 4  # Adjust based on your machine's capabilities\n",
    "\n",
    "if dev:\n",
    "    n = 3\n",
    "    target_widths, target_heights = zip(*[(x, x) for x in range(700, 800 + 1, 64)])\n",
    "    # target_widths, target_heights = zip(*[(x, x) for x in range(128, 3840 + 1, 64)])\n",
    "    for target_width, target_height in zip(target_widths, target_heights):\n",
    "        output_directory = f'{input_directory}/dev/{target_width}x{target_height}'\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        target_size = (target_width, target_height)\n",
    "        process_directory(input_directory, output_directory, target_size=(target_width, target_height), dev=dev, n=n)\n",
    "\n",
    "imgsz = int(input('Enter image size (e.g. 640): '))\n",
    "if imgsz != '':\n",
    "    print(f'Image size: {imgsz}')\n",
    "    output_directory = f'{input_directory}/{imgsz}x{imgsz}'\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    target_size = (imgsz, imgsz)\n",
    "    if parallel_process:\n",
    "        parallel_process(input_directory, output_directory, target_size, n_processes)\n",
    "    else:\n",
    "        process_directory(input_directory, output_directory, target_size, dev=dev)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def split_dataset(image_dir, annotation_dir, output_directory, train_ratio=0.8):\n",
    "    images = sorted([f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    annotations = sorted(os.listdir(annotation_dir))\n",
    "\n",
    "    # Ensure corresponding annotation files exist\n",
    "    images_with_annotations = []\n",
    "    annotations_filtered = []\n",
    "    for image in images:\n",
    "        annotation = image.rsplit('.', 1)[0] + '.txt'\n",
    "        if annotation in annotations:\n",
    "            images_with_annotations.append(image)\n",
    "            annotations_filtered.append(annotation)\n",
    "\n",
    "    # Split into train and valid sets\n",
    "    train_images, valid_images, train_annotations, valid_annotations = train_test_split(\n",
    "        images_with_annotations, annotations_filtered, train_size=train_ratio\n",
    "    )\n",
    "\n",
    "    # Function to copy files to a target directory\n",
    "    def copy_files(files, source_dir, target_dir):\n",
    "        for file in files:\n",
    "            shutil.copy(os.path.join(source_dir, file), os.path.join(target_dir, file))\n",
    "\n",
    "    # Create directories and copy files\n",
    "    os.makedirs(f'{output_directory}/train/images', exist_ok=True)\n",
    "    os.makedirs(f'{output_directory}/train/labels', exist_ok=True)\n",
    "    os.makedirs(f'{output_directory}/valid/images', exist_ok=True)\n",
    "    os.makedirs(f'{output_directory}/valid/labels', exist_ok=True)\n",
    "\n",
    "    copy_files(train_images, image_dir, f'{output_directory}/train/images')\n",
    "    copy_files(valid_images, image_dir, f'{output_directory}/valid/images')\n",
    "    copy_files(train_annotations, annotation_dir, f'{output_directory}/train/labels')\n",
    "    copy_files(valid_annotations, annotation_dir, f'{output_directory}/valid/labels')\n",
    "\n",
    "    if overwrite_yolo_dataset:\n",
    "        path = '/Users/eric/Desktop/2-Career/Projects/ObjectDetection/hockey/dataset/'\n",
    "        # overwrite the directories if they exist\n",
    "        os.makedirs(f'{path}/train/images', exist_ok=True)\n",
    "        os.makedirs(f'{path}/train/labels', exist_ok=True)\n",
    "        os.makedirs(f'{path}/valid/images', exist_ok=True)\n",
    "        os.makedirs(f'{path}/valid/labels', exist_ok=True)\n",
    "\n",
    "        copy_files(train_images, image_dir, f'{path}/train/images')\n",
    "        copy_files(valid_images, image_dir, f'{path}/valid/images')\n",
    "        copy_files(train_annotations, annotation_dir, f'{path}/train/labels')\n",
    "        copy_files(valid_annotations, annotation_dir, f'{path}/valid/labels')\n",
    "\n",
    "overwrite_yolo_dataset = True\n",
    "images_dir = f'{output_directory}/images'\n",
    "annotations_dir = f'{output_directory}/labels'\n",
    "split_dataset(images_dir, annotations_dir, output_directory, train_ratio=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
