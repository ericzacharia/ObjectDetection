{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook translated the COCO 1.0 JSON file export from CVAT into YOLO .txt files after annotating images on the CVAT website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '', 'id': 0, 'url': ''}\n",
      "{'contributor': '', 'date_created': '', 'description': '', 'url': '', 'version': '', 'year': ''}\n",
      "{'id': 1, 'name': 'license plate', 'supercategory': ''}\n",
      "{'id': 1, 'width': 3840, 'height': 2160, 'file_name': '100-00000.png', 'license': 0, 'flickr_url': '', 'coco_url': '', 'date_captured': 0}\n",
      "{'id': 1, 'image_id': 19, 'category_id': 1, 'segmentation': [], 'area': 5352.394699999999, 'bbox': [171.13, 881.1, 82.97, 64.51], 'iscrowd': 0, 'attributes': {'occluded': False, 'rotation': 0.0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'id': 19,\n",
       "  'width': 3840,\n",
       "  'height': 2160,\n",
       "  'file_name': '101-00006.png',\n",
       "  'license': 0,\n",
       "  'flickr_url': '',\n",
       "  'coco_url': '',\n",
       "  'date_captured': 0},\n",
       " {'id': 1,\n",
       "  'image_id': 19,\n",
       "  'category_id': 1,\n",
       "  'segmentation': [],\n",
       "  'area': 5352.394699999999,\n",
       "  'bbox': [171.13, 881.1, 82.97, 64.51],\n",
       "  'iscrowd': 0,\n",
       "  'attributes': {'occluded': False, 'rotation': 0.0}})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's start by loading the JSON file and examining its structure\n",
    "import json\n",
    "\n",
    "input_directory = '/Users/eric/Desktop/2-Career/Projects/ObjectDetection/coco_to_yolo'\n",
    "# Load the JSON content\n",
    "json_path = f'{input_directory}/61_200.json'\n",
    "with open(json_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Let's check the keys at the top level of the JSON structure, and the first image with an annotation\n",
    "first_annotation = json_data['annotations'][0]\n",
    "first_image_with_annotations = int(first_annotation['image_id'])\n",
    "\n",
    "json_data.keys()\n",
    "for key in json_data.keys():\n",
    "    if isinstance(json_data[key], list):\n",
    "        print(json_data[key][0])\n",
    "    else:\n",
    "        print(json_data[key])\n",
    "\n",
    "json_data['images'][first_image_with_annotations - 1], first_annotation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'labels_coco_to_yolo'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory for saving the .txt files\n",
    "output_labels_dir = f'{input_directory}/labels'\n",
    "output_images_dir = f'{input_directory}/images'\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "os.makedirs(output_images_dir, exist_ok=True)\n",
    "\n",
    "def normalize_coordinates(points, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Normalize the coordinates by dividing by the image width and height.\n",
    "    The points list is assumed to be in the format [x1, y1, x2, y2, ...].\n",
    "    \"\"\"\n",
    "    normalized_points = []\n",
    "    for i, point in enumerate(points):\n",
    "        normalized_point = point / img_width if i % 2 == 0 else point / img_height\n",
    "        normalized_point = round(normalized_point, 5)\n",
    "        normalized_points.append(normalized_point)\n",
    "    return normalized_points\n",
    "\n",
    "def process_annotation(ann, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Process a single annotation, returning a formatted string\n",
    "    containing the class (always 0) followed by the normalized segmentation points.\n",
    "    If segmentation is not available, use normalized bounding box coordinates.\n",
    "    \"\"\"\n",
    "    if 'segmentation' in ann and ann['segmentation']:\n",
    "        # Use segmentation if available, and normalize the points\n",
    "        points = [coord for segment in ann['segmentation'] for coord in segment]\n",
    "        normalized_points = normalize_coordinates(points, img_width, img_height)\n",
    "        return '0 ' + ' '.join(map(str, normalized_points))\n",
    "    else:\n",
    "        # Fall back to bounding box if segmentation is not available, and normalize\n",
    "        bbox = ann['bbox']\n",
    "        # Convert COCO bbox [x,y,width,height] format to [x1,y1,x2,y2] format\n",
    "        x_tl, y_tl, width, height = bbox\n",
    "        x_center, y_center = x_tl + width / 2, y_tl + height / 2\n",
    "        box_points = [x_center, y_center, width, height]\n",
    "        normalized_box_points = normalize_coordinates(box_points, img_width, img_height)\n",
    "        return '0 ' + ' '.join(map(str, normalized_box_points))\n",
    "\n",
    "def create_normalized_annotation_files(images, annotations):\n",
    "    \"\"\"\n",
    "    Create a .txt file for each image with normalized annotations.\n",
    "    \"\"\"\n",
    "    for img in images:\n",
    "        img_width, img_height = img['width'], img['height']  # Assuming these are always 3840x2160 for 4k images\n",
    "        # Create a .txt file for each image\n",
    "        file_path = os.path.join(output_dir, f\"{'.'.join(img['file_name'].split('.')[:-1])}.txt\")\n",
    "        with open(file_path, 'w') as file:\n",
    "            # Write annotations related to the image\n",
    "            for ann in annotations:\n",
    "                if ann['image_id'] == img['id']:\n",
    "                    file.write(process_annotation(ann, img_width, img_height) + '\\n')\n",
    "\n",
    "# Remove previous files to avoid confusion\n",
    "for filename in sorted(os.listdir(output_dir)):\n",
    "    if not os.path.isfile(filename):\n",
    "        continue\n",
    "    file_path = os.path.join(output_dir, filename)\n",
    "    os.remove(file_path)\n",
    "\n",
    "# Process the images and annotations from the JSON file with normalization\n",
    "create_normalized_annotation_files(json_data['images'], json_data['annotations'])\n",
    "\n",
    "# Provide the path to the directory containing the updated output files\n",
    "output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3034, 3034, '100-00000.png', '100-00000.txt')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "images = sorted(os.listdir(output_images_dir))\n",
    "labels = sorted(os.listdir(output_labels_dir))\n",
    "images_set = set(images)\n",
    "labels_set = set(labels)\n",
    "len(images), len(labels), images[0], labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, set())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_file_names = set()\n",
    "\n",
    "for image in images:\n",
    "    if image[:-4] + '.txt' not in labels:\n",
    "        mutual_file_names.add(image)\n",
    "\n",
    "for label in labels:\n",
    "    if label[:-4] + '.png' not in images:\n",
    "        mutual_file_names.add(label)\n",
    "\n",
    "len(mutual_file_names), mutual_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "images = sorted(os.listdir('images_coco_to_yolo'))\n",
    "labels = sorted(os.listdir('labels_coco_to_yolo'))\n",
    "for image, label in zip(images, labels):    \n",
    "    # check if it is a file:\n",
    "    if not os.path.isfile(os.path.join('images_coco_to_yolo', image)):\n",
    "        continue\n",
    "    if random.random() <= 0.8:\n",
    "        # move and replace if it already exists\n",
    "        shutil.move(os.path.join('images_coco_to_yolo', image), 'dataset/train/images')\n",
    "        shutil.move(os.path.join('labels_coco_to_yolo', label), 'dataset/train/labels')\n",
    "    else:\n",
    "        shutil.move(os.path.join('images_coco_to_yolo', image), 'dataset/valid/images')\n",
    "        shutil.move(os.path.join('labels_coco_to_yolo', label), 'dataset/valid/labels')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of True Negatives in train set: 30.76%\n",
      "Percentage of True Negatives in valid set: 29.13%\n"
     ]
    }
   ],
   "source": [
    "# See the proportion of images with no annotations (True Negatives)\n",
    "for folder in ['train', 'valid']:\n",
    "    image_dir = f'dataset/{folder}/images'\n",
    "    image_filenames = os.listdir(image_dir)\n",
    "    label_dir = f'dataset/{folder}/labels'\n",
    "    label_filenames = os.listdir(label_dir)\n",
    "    num_empty = 0\n",
    "    for label_filename in label_filenames:\n",
    "        with open(os.path.join(label_dir, label_filename), 'r') as file:\n",
    "            contents = file.read()\n",
    "            if not contents:\n",
    "                num_empty += 1\n",
    "    print(f'Percentage of True Negatives in {folder} set: {num_empty / len(label_filenames) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
